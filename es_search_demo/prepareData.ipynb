{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch_dsl import Document, Date, Integer, Float, Keyword, Text, GeoPoint, Object, InnerDoc, Nested\n",
    "from elasticsearch_dsl.connections import connections\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import datetime\n",
    "\n",
    "# create connection pool\n",
    "pooledConnection = connections.create_connection(hosts=['localhost'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# read the given file and parse the contents (from json to dict)\n",
    "def prepareDictFromJsonString(filename):\n",
    "    content = {}\n",
    "    \n",
    "    f = open(filename, 'r')\n",
    "    if f.mode == 'r':\n",
    "        content = json.loads(f.read())\n",
    "\n",
    "    return content\n",
    "\n",
    "# data structure\n",
    "#{\n",
    "# \"name\": \"Data Mining, Southeast Asia Edition\", # bookname   \n",
    "# \"authors\": [ \"Jiawei Han\" ], \n",
    "# \"publisher\": \"Elsevier\",\n",
    "# \"publish_date\": \"2006-04-06\",\n",
    "# \"desc\": \".....\",\n",
    "# \"isbn10\": \"...\",\n",
    "# \"isbn13\": \"...\",\n",
    "# \"pages\": 800,\n",
    "# \"print_type\": \"book\",\n",
    "# \"category\": [\"computer\"],\n",
    "# \"average_rating\": 3.5,\n",
    "# \"ratings_count\": 23,\n",
    "#    \"image\": \"http://books.google.com/books/content?id=AfL0t-YzOrEC&printsec=frontcover&img=1&zoom=5&edge=curl&source=gbs_api\",\n",
    "#    \"language\": \"en\"\n",
    "#}\n",
    "\n",
    "class GoogleBook(Document):\n",
    "    name = Text(analyzer='english', fields={'raw': Keyword()})\n",
    "    authors = Text(multi=True)\n",
    "    publisher = Text()\n",
    "    publish_date = Date()\n",
    "    desc = Text(analyzer='english')\n",
    "    isbn10 = Keyword()\n",
    "    isbn13 = Keyword()\n",
    "    pages = Integer()\n",
    "    print_type = Keyword(multi=True)\n",
    "    book_category = Keyword(multi=True)\n",
    "    average_rating = Float()\n",
    "    ratings_count = Integer()\n",
    "    image = Keyword()\n",
    "    language = Keyword(multi=True)\n",
    "    search_category = Text(analyzer='english', fields={'raw': Keyword()})\n",
    "    \n",
    "    class Index:\n",
    "        name = \"google_book_demo\"\n",
    "        \n",
    "    class Meta:\n",
    "        docType = \"_doc\"\n",
    "\n",
    "        \n",
    "# create Mappings\n",
    "GoogleBook.init()\n",
    "        \n",
    "    \n",
    "# search for book volumes based on given token / keyword (using Google books api)\n",
    "def searchForBookByApi(vocabDict):\n",
    "    URL = \"https://www.googleapis.com/books/v1/volumes\"\n",
    "    PARAMS = {\n",
    "        \"q\": \"\",\n",
    "        \"maxResults\": 20\n",
    "    }\n",
    "    entityList = []\n",
    "    \n",
    "    vocabList = vocabDict['vocabulary']\n",
    "    for catItem in vocabList:\n",
    "        searchCategory = catItem['category']\n",
    "        tokenList = catItem['tokens']\n",
    "        \n",
    "        for token in tokenList:\n",
    "            # add back the token for search\n",
    "            PARAMS['q'] = token\n",
    "            jsonData = requests.get(url=URL, params=PARAMS).json()\n",
    "            ###### PS...\n",
    "            # print(jsonData)\n",
    "            if 'items' in jsonData:\n",
    "                items = jsonData['items']\n",
    "            else:\n",
    "                items = []\n",
    "            \n",
    "            for item in items:\n",
    "                item = item['volumeInfo']\n",
    "                inst = GoogleBook(search_category=searchCategory)\n",
    "                # language\n",
    "                if 'language' in item:\n",
    "                    inst.language = item['language']\n",
    "                    \n",
    "                if 'title' in item:\n",
    "                    inst.name = item['title']\n",
    "                \n",
    "                if 'publisher' in item:\n",
    "                    inst.publisher = item['publisher']\n",
    "                    \n",
    "                # image\n",
    "                if 'imageLinks' in item and 'smallThumbnail' in item['imageLinks']:\n",
    "                    inst.image = item['imageLinks']['smallThumbnail']\n",
    "                \n",
    "                # description\n",
    "                if 'description' in item:\n",
    "                    inst.desc = item['description']\n",
    "                \n",
    "                # print type\n",
    "                if 'printType' in item:\n",
    "                    inst.print_type = item['printType']\n",
    "                \n",
    "                # authors array\n",
    "                if 'authors' in item:\n",
    "                    aList = item['authors']\n",
    "                    for a in aList:\n",
    "                        inst.authors.append(a)\n",
    "                    \n",
    "                # publish date\n",
    "                dateErr = False\n",
    "                if 'publishedDate' in item:\n",
    "                    try:\n",
    "                        inst.publish_date = datetime.datetime.strptime(item['publishedDate'], '%Y-%m-%d')\n",
    "                    except:\n",
    "                        dateErr = True\n",
    "\n",
    "                    if dateErr == True:\n",
    "                        try:\n",
    "                            dateErr = False\n",
    "                            inst.publish_date = datetime.datetime.strptime(item['publishedDate'], '%Y')\n",
    "                        except:\n",
    "                            dateErr = True\n",
    "\n",
    "                    if dateErr == True:\n",
    "                        try:\n",
    "                            dateErr = False                            \n",
    "                            inst.publish_date = datetime.datetime.strptime(item['publishedDate'], '%Y-%m')\n",
    "                        except:\n",
    "                            inst.publish_date = datetime.datetime.strptime('1970-01-01', '%Y-%m-%d')\n",
    "                    \n",
    "                            \n",
    "                # isbn10 and isbn13\n",
    "                if 'industryIdentifiers' in item:\n",
    "                    aList = item['industryIdentifiers']\n",
    "                    for a in aList:\n",
    "                        if a['type'] == 'ISBN_10':\n",
    "                            inst.isbn10 = a['identifier']\n",
    "                        elif a['type'] == 'ISBN_13':\n",
    "                            inst.isbn13 = a['identifier']\n",
    "                # category(s)\n",
    "                if 'categories' in item:\n",
    "                    aList = item['categories']\n",
    "                    for a in aList:\n",
    "                        inst.book_category.append(a)\n",
    "                # avg rating\n",
    "                if 'averageRating' in item:\n",
    "                    inst.average_rating = float(item['averageRating'])\n",
    "                else:\n",
    "                    inst.average_rating = 0.0\n",
    "                    \n",
    "                if 'ratingsCount' in item:\n",
    "                    inst.ratings_count = int(item['ratingsCount'])\n",
    "                else: \n",
    "                    inst.ratings_count = 0\n",
    "                    \n",
    "                if 'pageCount' in item: \n",
    "                    inst.pages = int(item['pageCount'])\n",
    "                else:\n",
    "                    inst.pages = 0\n",
    "                \n",
    "                entityList.append(inst)\n",
    "                \n",
    "            # end -- for (items from the result)\n",
    "        # end -- for (token within the vocabulary)\n",
    "    # end -- for (category object containing the tokens)\n",
    "    \n",
    "    return entityList\n",
    "\n",
    "\n",
    "def persistToES(entityList):\n",
    "    for item in entityList:\n",
    "        item.save()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start to persist...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# main flow\n",
    "\n",
    "vocabDict = prepareDictFromJsonString('vocabulary')\n",
    "entityList = searchForBookByApi(vocabDict)\n",
    "print('start to persist...')\n",
    "persistToES(entityList)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
